{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4843nC261ft"
      },
      "source": [
        "# Competitor Analysis Using Multi-Agent Retrieval-Augmented Generation (RAG) Collaborative System\n",
        "#Developer: Nilovna Chatterjee, PhD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4My69RA7CQa"
      },
      "source": [
        "## Business Context\n",
        "Performing competitor analysis with a Multi-Agent Retrieval-Augmented Generation (RAG) Collaborative System.\n",
        "\n",
        "## Problem Scenario\n",
        "Conducting a robust competitor analysis of a company is a time-consuming and research-intensive process that may be prone to errors for example, outdated information.\n",
        "\n",
        "Analysts spend significant time gathering data, identifying relevant competitors, and synthesizing insights into actionable recommendations.\n",
        "\n",
        "## Objective\n",
        "To address above mentioned challenges, a Multi-Agent Retrieval-Augmented Generation (RAG) Collaborative System is proposed.\n",
        "\n",
        "This system will perform competitor analysis of a given company by comparing it with its key rivals in the relevant industry using the latest available web data.\n",
        "\n",
        "Users will input a company name (e.g., \"Tesla\") and receive a well-structured report, comparing that company to its primary competitors (e.g., in the electric vehicle sector for Tesla), by leveraging a multi-agent collaborative architecture powered by RAG capabilities.\n",
        "\n",
        "The system should deliver rapid, accurate, and actionable insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwCScoL47LrD"
      },
      "source": [
        "## Solution Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8mBe9sJyLnG"
      },
      "source": [
        "A Multi-Agent Retrieval-Augmented Generation (RAG) Collaborative System is implemented using a sequential workflow pattern.\n",
        "\n",
        "This system automates competitor analysis by breaking down the task into distinct steps handled by specialized agents.\n",
        "\n",
        "The sequential pattern ensures each step builds on the previous one. Also, incorporating RAG to retrieve and augment data from a vector database for context-aware insights."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Below are the key components of the implementation:**\n",
        "\n",
        "### State Management\n",
        "\n",
        "The workflow uses a Pydantic-based state `CompetitiveAnalysisState` to track variables like company name, generated questions, search results, vectorstore status, and the final report."
      ],
      "metadata": {
        "id": "ixtWsLYDMwZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tools\n",
        "- `suggest_questions`: Generates relevant questions for competitor analysis using the LLM.\n",
        "- `fetch_search_results`: Searches the web via Tavily API to fetch answers for the questions.\n",
        "- `store_in_chromadb`: Stores question-answer pairs in ChromaDB for efficient retrieval.\n",
        "- `generate_report`: Uses RAG to query the vectorstore and draft a structured report.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CsxLH3-UJ2Gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents\n",
        "\n",
        "- `Question Generator Agent`: Validates the company, identifies its sector, and generates analysis questions.\n",
        "\n",
        "- `Data Retrieval and Storage Agent`: Fetches answers from the web and stores them in the vector database.\n",
        "\n",
        "- `Report Drafter Agent`: Retrieves stored data via RAG and generates a professional, actionable report with sections like Executive Summary, Company Overview, Key Competitors, Strengths/Weaknesses, Market Strategies, and Recommendations.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zk8uvkE5J4jb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Workflow (Sequential Pattern)\n",
        "\n",
        "The system uses LangGraph's StateGraph to define nodes for each agent.\n",
        "Edges connect the nodes sequentially as indicated below.\n",
        "\n",
        "`START → Question Generation → Data Retrieval/Storage → Report Drafting → END.`\n",
        "\n",
        "The final output is formatted competitive analysis report, displayed in Markdown for readability."
      ],
      "metadata": {
        "id": "6Pb9FBcMJ7X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the Libraries"
      ],
      "metadata": {
        "id": "H8VqB8oipcOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the libraries:\n",
        "- **openai==1.99.9** → Official OpenAI client library for interacting with GPT models.  \n",
        "- **langchain==0.3.27** → Core framework for building applications powered by LLMs.  \n",
        "- **langchain-openai==0.3.30** → LangChain integration for OpenAI models.  \n",
        "- **langchain-community==0.3.27** → Community-contributed LangChain modules (tools, integrations).  \n",
        "- **langgraph==0.6.4** → Build and manage multi-step workflows or agent graphs for LLM-powered systems.  \n",
        "- **langchain-chroma==0.2.5** → Connector for using **ChromaDB** as a vector database with LangChain.  \n",
        "- **chromadb==1.0.16** → Open-source vector database for storing and retrieving embeddings.  \n",
        "- **langchain-tavily==0.2.11** → Integration for the **Tavily API** (specialized web search + retrieval for RAG).  "
      ],
      "metadata": {
        "id": "XPxombNVpgeO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "Kgzcljar70t3"
      },
      "outputs": [],
      "source": [
        "#Install required packages\n",
        "!pip install -q openai==1.99.9 \\\n",
        "                langchain==0.3.27 \\\n",
        "                langchain-openai==0.3.30 \\\n",
        "                langchain-community==0.3.27 \\\n",
        "                langgraph==0.6.4 \\\n",
        "                langchain-chroma==0.2.5 \\\n",
        "                chromadb==1.0.16 \\\n",
        "                langchain-tavily==0.2.11"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the Environment (5 Marks)"
      ],
      "metadata": {
        "id": "fs0hnypH11LJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing the relevant packages**"
      ],
      "metadata": {
        "id": "-MyZalQIh8bH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "G_qmAz-dhG7w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "from typing import TypedDict, List, Optional, Dict, Tuple\n",
        "\n",
        "from pydantic import BaseModel, Field,ConfigDict\n",
        "\n",
        "import chromadb\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import StructuredTool\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.retrievers import BaseRetriever # Corrected from 'retriever' to 'retrievers'\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instantiating the required variables (5 Marks)**"
      ],
      "metadata": {
        "id": "g3lcxcBziBjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the environment variables.\n",
        "\n",
        "To securely connect with external APIs (like OpenAI and Tavily), we’ll set up our **environment variables**.  \n",
        "This ensures our API keys are not hard-coded directly in the notebook, keeping them safe.\n",
        "\n",
        "- **OPENAI_API_KEY**\n",
        "- **OPENAI_BASE_URL**\n",
        "- **TAVILY_API_KEY**\n",
        "\n",
        "After running this cell, your notebook will be able to access both **OpenAI** and **Tavily APIs** securely.\n"
      ],
      "metadata": {
        "id": "EjWZxOayoep6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KgAS2Gu5hWry"
      },
      "outputs": [],
      "source": [
        "# Set environment variables\n",
        "openai_api_key = userdata.get('OPEN_API_KEY')\n",
        "os.environ[\"OPEN_API_KEY\"] = openai_api_key\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "os.environ['OPENAI_BASE_URL'] = \"https://aibe.mygreatlearning.com/openai/v1\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our environment variables are set, let's initialize the **core models** we'll use in this project:\n",
        "\n",
        "Instantiating the LLM and the embedding model using the `ChatOpenAI` and `OpenAIEmbeddings` methods respectively."
      ],
      "metadata": {
        "id": "4fF2GNKMouXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rYDIh36KhiSb"
      },
      "outputs": [],
      "source": [
        "# Instantiate LLM\n",
        "llm = ChatOpenAI(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=os.environ['OPENAI_BASE_URL'],\n",
        "    model='gpt-4o-mini',\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Initialize OpenAIEmbeddings\n",
        "embedding_model = OpenAIEmbeddings(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=os.environ['OPENAI_BASE_URL'],\n",
        "    model='text-embedding-3-small'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pbcn8psvRfX"
      },
      "source": [
        "To enable **Retrieval-Augmented Generation (RAG)**, we need a place to store and query text embeddings.  \n",
        "Here, we'll use **ChromaDB**, an open-source vector database.\n",
        "\n",
        "Setting up the Chroma vector database client and a Chroma vector store collection for storing and retrieving search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3lCQrlRYhnUN"
      },
      "outputs": [],
      "source": [
        "# ChromaDB set up Persistent client\n",
        "#Set up Vector Store\n",
        "\n",
        "# ChromaDB Setup\n",
        "chromadb_client = chromadb.PersistentClient(path=\"./assist_db\")\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"search_result_collection\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"},\n",
        "    embedding_function=embedding_model,\n",
        "    client=chromadb_client,\n",
        "    persist_directory=\"./assist_db\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze7HEuixkakZ"
      },
      "source": [
        "# **State Definitions (6 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4My_PeWv47V"
      },
      "source": [
        "Lets define the Pydantic models for structured outputs - 'QuestionSuggestion' and the overall state - 'CompetitiveAnalysisState'  .\n",
        "State Definition ensure type safety and structure the data passed between agents and nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV7um4JAkoKf"
      },
      "source": [
        "## **QuestionSuggestion (3 Marks)**\n",
        "\n",
        "\n",
        "This model will help ensure that the responses from the LLM follow a **consistent format**, making them easier to validate and use later.\n",
        "\n",
        "- Create a class that inherits from `BaseModel`.  \n",
        "- Fields include:\n",
        "  - **sector** → The industry sector of the company.  \n",
        "  - **is_valid_company** →  A boolean flag for whether the company name is recognized.  \n",
        "  - **questions** → A list of suggested competitive analysis questions.  \n",
        "  - **error_message** → Optional field to capture any errors that occur.  \n",
        "\n",
        "- The `Field()` argument ensures that **default values** and **descriptions** are available for each attribute.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "voPFNCB6kpeW"
      },
      "outputs": [],
      "source": [
        "# First, define the constant as required\n",
        "MAX_NUM_OF_QUESTIONS = 40\n",
        "\n",
        "class QuestionSuggestion(BaseModel):\n",
        "    \"\"\"\n",
        "    Structured output model for competitive analysis questions\n",
        "    \"\"\"\n",
        "    sector: str = Field(None, description=\"The industry sector the company operates in\")\n",
        "    is_valid_company: bool = Field(..., description=\"Whether the provided company name is valid/known\")\n",
        "    questions: List[str] = Field(default_factory=list, description=\"List of generated competitive analysis questions\")\n",
        "    error_message: Optional[str] = Field(None, description=\"Error message if any step fails\")\n",
        "\n",
        "class CompetitiveAnalysisState(BaseModel):\n",
        "    company_name: str\n",
        "    # Now MAX_NUM_OF_QUESTIONS is defined and can be used as a default\n",
        "    max_num_of_questions: int = MAX_NUM_OF_QUESTIONS\n",
        "    sector: Optional[str] = None\n",
        "    is_valid_company: Optional[bool] = None\n",
        "    question_list: Optional[List[str]] = None\n",
        "    qna_results: Optional[List[Dict]] = None\n",
        "    vectorstore: Chroma = vectorstore\n",
        "    chromadb_insert_status: Optional[bool] = None\n",
        "    report: Optional[str] = None\n",
        "    error_message: Optional[str] = None\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe2TuraKk2w1"
      },
      "source": [
        "## **Competitive Analysis State (3 marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we’ll create a state object for keeping track off the competitive analysis that keeps track of all the information our pipeline generates and updates during the competitive analysis workflow.\n",
        "\n",
        "This will act as a “shared memory” object, making it easier to pass data between steps in the system.\n",
        "\n",
        "- Fields include:\n",
        "  - **company_name** → The company being analyzed.  \n",
        "  - **max_num_of_questions** → The maximum number of questions to generate (use a constant as the default).  \n",
        "  - **sector** → The industry sector (optional).  \n",
        "  - **is_valid_company** → Boolean flag to mark if the company is recognized (optional).  \n",
        "  - **question_list** → List of generated analysis questions (optional).  \n",
        "  - **qna_results** → Stores answers to questions as a list of dictionaries (optional).  \n",
        "  - **vectorstore** → Chroma vector database instance for retrieval.  \n",
        "  - **chromadb_insert_status** → Tracks whether data was successfully stored in Chroma (optional).  \n",
        "  - **report** → Final competitive analysis report (optional).  \n",
        "  - **error_message** → Captures any error details (optional).\n",
        "\n",
        "- The `model_config` setting allows **non-Pydantic types** (e.g., Chroma objects).\n"
      ],
      "metadata": {
        "id": "M2aiXVI5wY_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "KydzdI35xFpp"
      },
      "outputs": [],
      "source": [
        "#Setting maximum limit to number of genetated questions\n",
        "MAX_NUM_OF_QUESTIONS = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "righFChlkhoz"
      },
      "outputs": [],
      "source": [
        "class CompetitiveAnalysisState(BaseModel):\n",
        "    company_name: str\n",
        "    max_num_of_questions: int # Set up to Maximum Number of Questions\n",
        "    sector: Optional[str] = None\n",
        "    is_valid_company: Optional[bool] = None\n",
        "    question_list: Optional[List[str]] = None\n",
        "    qna_results: Optional[List[Dict]] = None\n",
        "    vectorstore: Chroma = vectorstore\n",
        "    chromadb_insert_status: Optional[bool] = None\n",
        "    report: Optional[str] = None\n",
        "    error_message: Optional[str] = None\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wScSrtJvk7sw"
      },
      "source": [
        "# **Tools (13 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If0Dez8ElGr2"
      },
      "source": [
        "## **Tavily Search Tool (1 Mark)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enrich our competitive analysis, **Tavily Search** will be used to fetch **relevant company information** that can later be embedded into our vector store and used for RAG.\n",
        "The following code\n",
        "- Initializes a `TavilySearch` instance with the following parameters:\n",
        "  - **max_results** → The maximum number of results to return  \n",
        "  - **include_answer** → Whether to include a synthesized answer from Tavily.  \n",
        "  - **include_raw_content** → Whether to return raw page content along with the results.\n",
        "  - **search_depth** → Set the level of search (`\"basic\"` or `\"advanced\"`).  "
      ],
      "metadata": {
        "id": "mYYWcreqw4Py"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "962hM9XQk99n"
      },
      "outputs": [],
      "source": [
        "# Tavily Search Tool (1 Mark)\n",
        "search = TavilySearch(max_results=2, include_answer=True, include_raw_content=True, search_depth=\"advanced\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lem7cANnzCqu"
      },
      "source": [
        "Below section defines the tools used by the agents for,\n",
        "- Suggesting questions,\n",
        "- Fetching search results,\n",
        "- Storing data in ChromaDB, and\n",
        "- Generating the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjJI-QEYlNSH"
      },
      "source": [
        "## **Suggest Questions Tool (3 marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The Suggest Questions Tool is a **custom LangChain tool** that uses an LLM to generate structured competitive analysis questions for a given company.  \n",
        "\n",
        "This tool will serve as the **entry point** in our pipeline for validating company information and generating insightful prompts for deeper analysis.\n",
        "\n",
        "The function `suggest_questions` contains a  **prompt** that instructs the LLM to:\n",
        "     - Validate if the company is real/known.  \n",
        "     - Identify its sector.  \n",
        "     - Generate targeted competitor analysis questions (e.g., competitors, pricing, supply chain, strengths/weaknesses, market opportunities) and **invokes the LLM** with a structured output format (using the `QuestionSuggestion` model).  \n",
        "The `@tool` decorator ensures that it can be called by agents within LangChain.\n"
      ],
      "metadata": {
        "id": "bhX4kYwbxZMN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "G8er_5gPlAaM"
      },
      "outputs": [],
      "source": [
        " # Define LangChain Tool\n",
        "# Suggest Questions Tool\n",
        "@tool\n",
        "def suggest_questions(company_name: str, max_num_of_questions: int) -> str:\n",
        "    \"\"\"Suggest list containing questions for the given company name.\"\"\"\n",
        "    # Ensure the tool respects the absolute limit of 40 defined in the state\n",
        "    limit = min(max_num_of_questions, 40)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "For the given company name: {company_name}\n",
        "\n",
        "1. Validate if it's a known company: Set 'is_valid_company' to true if it's a recognized company; otherwise, false.\n",
        "2. Identify its primary 'sector'.\n",
        "3. Generate up to {limit} targeted questions for a comprehensive competitor analysis. Focus on areas that enable detailed comparisons and insights:\n",
        "   - Identifying key competitors and market share.\n",
        "   - Comparing products, pricing, technology, and supply chain.\n",
        "   - Analyzing strengths, weaknesses, and differentiators.\n",
        "   - Exploring market trends and growth opportunities.\n",
        "Ensure questions support a structured report with sections like Executive Summary, Company Overview, Key Competitors, Strengths/Weaknesses, and Recommendations.\n",
        "\"\"\"\n",
        "    print(\"[INSIDE TOOL] suggest_questions\")\n",
        "    try:\n",
        "        # Enforce structured output using the Pydantic model\n",
        "        structured_llm = llm.with_structured_output(QuestionSuggestion)\n",
        "        result = structured_llm.invoke(prompt)\n",
        "\n",
        "        print(f\"[Identified SECTOR] {result.sector}\")\n",
        "        print(f\"[IS VALID COMPANY] {result.is_valid_company}\")\n",
        "        print(f\"[QUESTION GENERATED LIST] {len(result.questions)} questions\")\n",
        "\n",
        "        return json.dumps({\n",
        "            \"sector\": str(result.sector),\n",
        "            \"is_valid_company\": bool(result.is_valid_company),\n",
        "            \"questions\": result.questions\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        return json.dumps({\n",
        "            \"sector\": \"\",\n",
        "            \"is_valid_company\": False,\n",
        "            \"questions\": [],\n",
        "            \"error_message\": str(e)\n",
        "        })\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNzs0AeVlbg8"
      },
      "source": [
        "## **Fetch Search Result Tool (3 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Fetch Search Result tool will take each question, query the **Tavily Search API**, and collect the results.\n",
        "\n",
        "The function **iterates** through the `question_list` and for each question:\n",
        "     - Call `search.invoke({\"query\": question})` to get Tavily search results.  \n",
        "     - Check if the result contains an `\"answer\"`.  \n",
        "     - Store the pair (`question`, `answer`) in a list of dictionaries.  \n",
        "Additionally, the function can:\n",
        "- **Handle missing answers** by storing an empty string.\n",
        "- Handle errors** with a `try/except` block and log them for debugging.  \n",
        "- Return the **final results as a JSON string**."
      ],
      "metadata": {
        "id": "XMXXjiy2x7dv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "zhkX_Rq1lXem"
      },
      "outputs": [],
      "source": [
        "# Define LangChain Tool\n",
        "# Fetch Search Result Tool (3 Marks)\n",
        "@tool\n",
        "def fetch_search_results(question_list: List[str]) -> str:\n",
        "    \"\"\"Iterate through question_list and search for answers.\"\"\"\n",
        "    results = []\n",
        "    for question in question_list:\n",
        "        try:\n",
        "            search_result = search.invoke({\"query\": question})\n",
        "            answer = search_result.get('answer', \"\").lower()\n",
        "            results.append({\"question\": question, \"answer\": answer})\n",
        "        except Exception as e:\n",
        "            results.append({\"question\": question, \"answer\": \"\"})\n",
        "    return json.dumps(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5d2vWZpleK6"
      },
      "source": [
        "## **Store in ChromaDB Tool (4 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After fetching question-answer pairs, they must be stored in **ChromaDB** so they can later be retrieved during the analysis.  \n",
        "This tool will embed the answers and insert them into the vector store along with metadata for traceability.\n",
        "\n",
        "The function `store_in_chromadb`:\n",
        "- Loop through each question–answer dictionary.  \n",
        "- **Skip empty answers** (don’t embed/store them).  \n",
        "- For valid answers:  \n",
        "    - Create a `documents` list containing the answer text.  \n",
        "    - Create `metadatas` with fields such as:  \n",
        "        - `question` → the original question  \n",
        "        - `source_type` → `\"answer\"`  \n",
        "        - `search_success` → whether a valid answer was found  \n",
        "    - Create unique `ids` for each entry (e.g., `\"doc_1\"`, `\"doc_2\"`).  \n",
        "- Use `vectorstore.add_texts()` to insert documents, metadata, and IDs into ChromaDB.  "
      ],
      "metadata": {
        "id": "Gi9WOVQXx-GX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5R1NaDWglcqR"
      },
      "outputs": [],
      "source": [
        "# Define LangChain Tool\n",
        "# Store in ChromaDB Tool\n",
        "@tool\n",
        "def store_in_chromadb(qna_results: List[Dict]) -> str:\n",
        "    \"\"\"Stores a list of question-answer dictionaries in ChromaDB.\"\"\"\n",
        "    success_count = 0\n",
        "    for index, d in enumerate(qna_results, start=1):\n",
        "        try:\n",
        "            if not d[\"answer\"]: continue\n",
        "            vectorstore.add_texts(texts=[d[\"answer\"]],\n",
        "                                  metadatas=[{\"question\": d[\"question\"], \"source_type\": \"answer\"}],\n",
        "                                  ids=[f\"doc_{index}_{random.randint(0,1000)}\"])\n",
        "            success_count += 1\n",
        "        except Exception: continue\n",
        "    return json.dumps({\"chromadb_insert_status\": success_count > 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-khwaD1lh7W"
      },
      "source": [
        "## **Generate Report Tool (2 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `generate_report` tool will be used to define precisely how to use retrieved context for generating the report by\n",
        "- using the retrieved context as the primary source and comparing competitors across dimensions (market share, products, pricing, tech, supply chain, customer sentiment).\n",
        "- highlighting differentiators and actionable strategies.\n",
        "- structuring the final output into the named sections and citing context where relevant.\n",
        "\n",
        "The functions builds a `human` message that requests a report for the given `company_name` and `sector` and includes a `{context}` placeholder which will be filled at runtime with retrieved documents from the vectorstore and combine messages into a `ChatPromptTemplate.from_messages([...])`"
      ],
      "metadata": {
        "id": "VfUwCQOIx-18"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "LGzYb6iglibg"
      },
      "outputs": [],
      "source": [
        "# Define LangChain Tool\n",
        "# Generate Report Tool\n",
        "@tool\n",
        "def generate_report(company_name: str, sector: str) -> ChatPromptTemplate:\n",
        "    \"\"\"Generate a competitive analysis report using RAG.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Role: You are an advanced competitor analysis tool...\"),\n",
        "        (\"human\", f\"Generate report for {company_name} in the {sector} sector using retrieved context: {{context}}\")\n",
        "    ])\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boiMDjICpvOg"
      },
      "source": [
        "# **Agents (26 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize the Agents (2 Marks)**"
      ],
      "metadata": {
        "id": "qQexi2-VjWC_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z36M8Ecr0Q3C"
      },
      "source": [
        "Below section creates reactive agents using LangChain's create_react_agent. Each agent is assigned specific tools:\n",
        "- question_generator_agent: Uses suggest_questions tool.\n",
        "- data_retrieval_storage_agent: Uses fetch_search_results and store_in_chromadb tool.\n",
        "- report_drafter_agent: Uses generate_report tool."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Agents (2 Marks)\n",
        "question_generator_agent = create_react_agent(llm, tools=[suggest_questions])\n",
        "data_retrieval_storage_agent = create_react_agent(llm, tools=[fetch_search_results, store_in_chromadb])\n",
        "report_drafter_agent = create_react_agent(llm, tools=[generate_report])"
      ],
      "metadata": {
        "id": "k-joe-frcnyO"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b5HsRd0p0c9"
      },
      "source": [
        "### Questions Generator Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "q_3kPPgspyop"
      },
      "outputs": [],
      "source": [
        "# Question Generator Node (6 Marks)\n",
        "def run_question_generator(state: CompetitiveAnalysisState) -> CompetitiveAnalysisState:\n",
        "    print(\"[NODE]: run_question_generator\")\n",
        "    human_message_content = f\"Company: {state.company_name}, Max: {state.max_num_of_questions}\"\n",
        "    print(f\"Invoking question_generator_agent with: {human_message_content}\")\n",
        "    response = question_generator_agent.invoke({\"messages\": [HumanMessage(content=human_message_content)]})\n",
        "\n",
        "    tool_output_json_str = None\n",
        "    # Iterate through messages in reverse to find the tool output for 'suggest_questions'\n",
        "    for msg in reversed(response.get(\"messages\", [])):\n",
        "        # LangGraph typically wraps tool outputs in a ToolMessage with the tool's name\n",
        "        if hasattr(msg, \"type\") and msg.type == \"tool\" and hasattr(msg, \"name\") and msg.name == \"suggest_questions\":\n",
        "            tool_output_json_str = msg.content\n",
        "            break\n",
        "\n",
        "    if tool_output_json_str is None:\n",
        "        state.error_message = \"Could not find valid JSON output from 'suggest_questions' tool. Agent response: \" \\\n",
        "                              + str([m.type for m in response.get(\"messages\", [])])\n",
        "        print(f\"[ERROR]: {state.error_message}\")\n",
        "        # Set default values\n",
        "        state.sector = None\n",
        "        state.is_valid_company = False\n",
        "        state.question_list = []\n",
        "        return state\n",
        "\n",
        "    print(f\"Attempting to parse JSON from tool output: {tool_output_json_str[:200]}...\")\n",
        "\n",
        "    try:\n",
        "        output = json.loads(tool_output_json_str)\n",
        "\n",
        "        state.sector = output.get('sector')\n",
        "        state.is_valid_company = output.get('is_valid_company', False)\n",
        "        state.question_list = output.get('questions', [])\n",
        "        # Capture error_message from the tool's structured output if present\n",
        "        state.error_message = output.get('error_message')\n",
        "\n",
        "        if not state.is_valid_company and not state.error_message:\n",
        "            state.error_message = f\"Company '{state.company_name}' not recognized or valid, and no specific error from tool.\"\n",
        "            print(f\"[WARNING]: {state.error_message}\")\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        state.error_message = f\"Failed to parse JSON output from 'suggest_questions' tool. Content: '{tool_output_json_str[:200]}...'. Error: {str(e)}\"\n",
        "        print(f\"[ERROR]: {state.error_message}\")\n",
        "        state.sector = None\n",
        "        state.is_valid_company = False\n",
        "        state.question_list = []\n",
        "    except Exception as e:\n",
        "        state.error_message = f\"An unexpected error occurred after parsing tool output: {str(e)}\"\n",
        "        print(f\"[ERROR]: {state.error_message}\")\n",
        "        state.sector = None\n",
        "        state.is_valid_company = False\n",
        "        state.question_list = []\n",
        "\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a7cmKnWp47X"
      },
      "source": [
        "### Data Retrieval & Storage Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "kvuGMDPDp5XA"
      },
      "outputs": [],
      "source": [
        "# Data Retrieval & Storage Node (6 Marks)\n",
        "def run_data_retrieval_storage(state: CompetitiveAnalysisState) -> CompetitiveAnalysisState:\n",
        "    print(\"[NODE]: run_data_retrieval_storage\")\n",
        "    if not state.question_list:\n",
        "        state.error_message = \"No questions generated.\"\n",
        "        return state\n",
        "\n",
        "    human_message_content = f\"Questions: {state.question_list}\"\n",
        "    print(f\"Invoking data_retrieval_storage_agent with: {human_message_content}\")\n",
        "    response = data_retrieval_storage_agent.invoke({\"messages\": [HumanMessage(content=human_message_content)]})\n",
        "\n",
        "    qna_results_from_tool = None\n",
        "    chromadb_status_from_tool = None\n",
        "\n",
        "    # Iterate through messages to find specific tool outputs\n",
        "    # Iterate in reverse as the latest tool outputs are usually towards the end\n",
        "    for msg in reversed(response.get(\"messages\", [])):\n",
        "        if hasattr(msg, \"type\") and msg.type == \"tool\" and hasattr(msg, \"name\"):\n",
        "            if msg.name == \"fetch_search_results\":\n",
        "                try:\n",
        "                    # Assuming fetch_search_results returns a JSON string of List[Dict]\n",
        "                    qna_results_from_tool = json.loads(msg.content)\n",
        "                    print(f\"[FETCH SEARCH RESULTS]: Found {len(qna_results_from_tool)} results.\")\n",
        "                except json.JSONDecodeError as e:\n",
        "                    state.error_message = f\"Failed to parse fetch_search_results output: {str(e)}\"\n",
        "                    print(f\"[ERROR]: {state.error_message}\")\n",
        "                # Only extract the first occurrence (most recent if iterating in reverse)\n",
        "                if qna_results_from_tool is not None: continue # Skip if already found\n",
        "\n",
        "            elif msg.name == \"store_in_chromadb\":\n",
        "                try:\n",
        "                    # Assuming store_in_chromadb returns a JSON string of Dict {\"chromadb_insert_status\": bool}\n",
        "                    chromadb_output = json.loads(msg.content)\n",
        "                    chromadb_status_from_tool = chromadb_output.get(\"chromadb_insert_status\", False)\n",
        "                    print(f\"[CHROMADB INSERT STATUS]: {chromadb_status_from_tool}\")\n",
        "                except json.JSONDecodeError as e:\n",
        "                    state.error_message = f\"Failed to parse store_in_chromadb output: {str(e)}\"\n",
        "                    print(f\"[ERROR]: {state.error_message}\")\n",
        "                # Only extract the first occurrence (most recent if iterating in reverse)\n",
        "                if chromadb_status_from_tool is not None: continue # Skip if already found\n",
        "\n",
        "\n",
        "    # Update state based on extracted tool outputs\n",
        "    if qna_results_from_tool is None:\n",
        "        state.error_message = state.error_message or \"Could not find valid output from 'fetch_search_results' tool.\"\n",
        "        print(f\"[ERROR]: {state.error_message}\")\n",
        "        state.qna_results = [] # Ensure it's an empty list if not found\n",
        "    else:\n",
        "        state.qna_results = qna_results_from_tool\n",
        "\n",
        "    if chromadb_status_from_tool is None:\n",
        "        state.error_message = state.error_message or \"Could not find valid output from 'store_in_chromadb' tool.\"\n",
        "        print(f\"[ERROR]: {state.error_message}\")\n",
        "        state.chromadb_insert_status = False # Ensure it's False if not found\n",
        "    else:\n",
        "        state.chromadb_insert_status = chromadb_status_from_tool\n",
        "\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFYh4QxyqLXR"
      },
      "source": [
        "### Report Drafter Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-cYaatqSqNZJ"
      },
      "outputs": [],
      "source": [
        "# Report Drafter Node (6 Marks)\n",
        "def run_report_drafter(state: CompetitiveAnalysisState) -> CompetitiveAnalysisState:\n",
        "    retriever = state.vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
        "    docs = retriever.invoke(f\"Competitive analysis for {state.company_name}\")\n",
        "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "    prompt_template = generate_report.invoke({\"company_name\": state.company_name, \"sector\": state.sector})\n",
        "    chain = prompt_template | llm\n",
        "    state.report = chain.invoke({\"context\": context}).content\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUIP2_r-qQ8w"
      },
      "source": [
        "# **Defining the Nodes (18 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yHBcjsdqhbj"
      },
      "source": [
        "## **Question Generator Node (6 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question Generator Node - Generates questions and updates state."
      ],
      "metadata": {
        "id": "EsM4j69XEWlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The run_question_generator node invokes the question-generation agent to produce structured JSON output and then parses that output to update the pipeline state by:\n",
        "- invoking the agent with a short system+human message (company name, max questions) and retrieving the agent response.\n",
        "- searching responses in reverse for the last JSON block (to find the structured payload) and using json.loads to parse it.\n",
        "- updating CompetitiveAnalysisState fields: sector, is_valid_company, question_list, and error_message.\n",
        "- handling errors and parsing failures gracefully by logging the issue and setting safe defaults (sector=\"\", is_valid_company=False, question_list=[], error_message=<error>).\n",
        "- returning the updated state for downstream nodes to consume."
      ],
      "metadata": {
        "id": "VORbhvnx5mmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_question_generator(state: CompetitiveAnalysisState) -> CompetitiveAnalysisState:\n",
        "    print(\"[NODE]: run_question_generator\")\n",
        "    messages = [\n",
        "        SystemMessage(content=\"Generate questions for competitive analysis.\"),\n",
        "        HumanMessage(content=f\"Company: {state.company_name}, Max questions: {state.max_num_of_questions}\")\n",
        "    ]\n",
        "    try:\n",
        "        # Invoke the question generator agent using the .invoke method\n",
        "        response = question_generator_agent.invoke({\"messages\": messages})\n",
        "\n",
        "        # Find the last message with valid JSON content\n",
        "        last_message = None\n",
        "        for msg in reversed(response[\"messages\"]):\n",
        "            if hasattr(msg, 'content') and isinstance(msg.content, str):\n",
        "                content = msg.content.strip()\n",
        "                # Handle markdown code blocks if the LLM wraps the JSON\n",
        "                if \"```json\" in content:\n",
        "                    content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "                elif \"```\" in content:\n",
        "                    content = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "                if content.startswith('{'):\n",
        "                    last_message = content\n",
        "                    break\n",
        "\n",
        "        if last_message is None:\n",
        "            last_message = response[\"messages\"][-1].content if response[\"messages\"] else \"\"\n",
        "            print(f\"[WARNING]: No valid JSON message found, using last message: {last_message}\")\n",
        "\n",
        "        try:\n",
        "            output = json.loads(last_message)\n",
        "            # Update state with parsed values\n",
        "            state.sector = output.get(\"sector\", \"\")\n",
        "            state.is_valid_company = output.get(\"is_valid_company\", False)\n",
        "            state.question_list = output.get(\"questions\", [])\n",
        "            state.error_message = output.get(\"error_message\", None)\n",
        "\n",
        "            print(f\"[PARSED OUTPUT]: sector={state.sector}, is_valid_company={state.is_valid_company}, questions={len(state.question_list)}\")\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"[ERROR]: Failed to parse JSON: {str(e)}\")\n",
        "            state.error_message = f\"Failed to parse JSON: {str(e)}\"\n",
        "            state.sector = \"\"\n",
        "            state.is_valid_company = False\n",
        "            state.question_list = []\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Question generator agent failed: {str(e)}\")\n",
        "        state.error_message = str(e)\n",
        "    return state"
      ],
      "metadata": {
        "id": "seSEmdJ2d1xp"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNuEqXEZqr7R"
      },
      "source": [
        "## **Data Retrieval and Storage Node (6 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Node fetches and stores the search results.\n",
        "\n",
        "The run_data_retrieval_storage node fetches answers for generated questions and stores them in ChromaDB, then updates the pipeline state by:\n",
        "- verifying questions exist and short-circuiting with an error if none were generated.\n",
        "- invoking the data_retrieval_storage agent with a short system+human message (questions) and retrieving the agent response.\n",
        "- parsing the last message as JSON to populate state.qna_results (the list of question–answer dicts).\n",
        "- extracting the `store_in_chromadb` tool call output from `response[\"messages\"][-1].tool_calls` (if present) to set state.chromadb_insert_status, with a fallback to read `chromadb_insert_status` from the parsed last message.\n",
        "handling JSON parse errors by setting state.error_message to a descriptive message.\n",
        "- returning the updated CompetitiveAnalysisState for downstream nodes to consume.\n"
      ],
      "metadata": {
        "id": "RYUWLallEJJL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "IkI17OKLqsSb"
      },
      "outputs": [],
      "source": [
        "def run_data_retrieval_storage(state: CompetitiveAnalysisState) -> CompetitiveAnalysisState:\n",
        "    print(\"[NODE]: run_data_retrieval_storage\")\n",
        "    if not state.question_list:\n",
        "        state.error_message = \"No questions generated.\"\n",
        "        return state\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=\"Fetch search results and store in vector DB.\"),\n",
        "        HumanMessage(content=f\"Questions: {state.question_list}\")\n",
        "    ]\n",
        "\n",
        "    # Invoke the data retrieval and storage agent\n",
        "    response = data_retrieval_storage_agent.invoke({\"messages\": messages})\n",
        "\n",
        "    # We need to find the specific outputs from the different tools in the message history\n",
        "    found_qna_results = []\n",
        "    found_insert_status = False\n",
        "\n",
        "    for msg in response[\"messages\"]:\n",
        "        if hasattr(msg, 'content') and isinstance(msg.content, str):\n",
        "            try:\n",
        "                # Attempt to parse the message content as JSON\n",
        "                data = json.loads(msg.content)\n",
        "\n",
        "                # If it's a list, it's the output from fetch_search_results\n",
        "                if isinstance(data, list):\n",
        "                    found_qna_results = data\n",
        "\n",
        "                # If it's a dict with the status key, it's from store_in_chromadb\n",
        "                elif isinstance(data, dict) and \"chromadb_insert_status\" in data:\n",
        "                    found_insert_status = data[\"chromadb_insert_status\"]\n",
        "            except (json.JSONDecodeError, TypeError):\n",
        "                # Skip messages that aren't JSON (like conversational filler)\n",
        "                continue\n",
        "\n",
        "    # Update the state with the correctly identified data types\n",
        "    state.qna_results = found_qna_results\n",
        "    state.chromadb_insert_status = found_insert_status\n",
        "\n",
        "    # If no results were found, log an error\n",
        "    if not found_qna_results:\n",
        "        state.error_message = \"Failed to retrieve any Q&A results from search.\"\n",
        "\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f40_3Odhq2f3"
      },
      "source": [
        "## **Report Drafter Node (6 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below Node generates the report leveraging RAG and prints a preview.\n",
        "\n",
        "The run_report_drafter node builds a RAG-powered report by retrieving stored Q&A context and invoking the report-generation prompt, then updates the pipeline state by:\n",
        "- creating a retriever from state.vectorstore (search_kwargs={\"k\": 10}) and querying it for competitive-analysis documents for the company.\n",
        "- handling the \"no documents\" case by setting state.report and state.error_message and short-circuiting.\n",
        "- concatenating retrieved documents' `page_content` into a single `context` string for the LLM.\n",
        "- invoking the `generate_report` tool to obtain a `ChatPromptTemplate` (expects a prompt template, not a final string).\n",
        "- validating the returned object is a `ChatPromptTemplate`; on mismatch, set `state.error_message` and `state.report` appropriately and return.\n",
        "- composing the prompt template with the LLM (e.g., `chain = prompt_template | llm`) and invoking the chain with `{\"context\": context}` to produce the report.\n",
        "storing the generated report in `state.report`, logging a brief preview, and handling any exceptions by setting `state.error_message` and a failure `state.report`.\n",
        "- returning the updated CompetitiveAnalysisState for downstream consumption.\n"
      ],
      "metadata": {
        "id": "a2RVvxWYCQv6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "VLT3DKkcq22F"
      },
      "outputs": [],
      "source": [
        "def run_report_drafter(state: CompetitiveAnalysisState) -> CompetitiveAnalysisState:\n",
        "    print(\"[NODE]: run_report_drafter\")\n",
        "    try:\n",
        "        retriever = state.vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
        "        retrieved_docs = retriever.invoke(f\"Competitive analysis data for {state.company_name}\")\n",
        "        if not retrieved_docs:\n",
        "            state.report = \"No data found in vectorstore for report generation.\"\n",
        "            state.error_message = \"No data found in vectorstore for report generation.\"\n",
        "            print(\"[WARNING]: No documents retrieved for report generation.\")\n",
        "            return state\n",
        "\n",
        "        context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "        print(\"[RETRIEVED CONTEXT]:\", context[:200] + \"...\" if len(context) > 200 else context)\n",
        "\n",
        "        # Directly invoke the generate_report tool to get the prompt template\n",
        "        prompt_template = generate_report.invoke({\n",
        "            \"company_name\": state.company_name, # Access company_name from state\n",
        "            \"sector\": state.sector # Access sector from state\n",
        "        })\n",
        "\n",
        "        # Ensure prompt_template is a ChatPromptTemplate\n",
        "        if not isinstance(prompt_template, ChatPromptTemplate):\n",
        "            state.error_message = f\"Expected ChatPromptTemplate, got {type(prompt_template)}\"\n",
        "            state.report = f\"Failed to generate report: Invalid prompt template type.\"\n",
        "            print(f\"[ERROR]: {state.error_message}\") # Log the specific error message\n",
        "            return state\n",
        "\n",
        "        # Create a chain and invoke it with the context\n",
        "        chain = prompt_template | llm\n",
        "        # Invoke the chain with the concatenated context string\n",
        "        report_content = chain.invoke({\"context\": context})\n",
        "\n",
        "        # Extract the text content from the AI Message and save to state\n",
        "        state.report = report_content.content\n",
        "        print(\"[REPORT GENERATED]:\", state.report[:200] + \"...\" if len(state.report) > 200 else state.report)\n",
        "\n",
        "    except Exception as e:\n",
        "        state.error_message = f\"Report drafter agent failed: {str(e)}\"\n",
        "        state.report = f\"Failed to generate report: {str(e)}\"\n",
        "        print(f\"[ERROR]: Report drafter agent failed: {str(e)}\")\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGmiHFTlrQNM"
      },
      "source": [
        "# **Workflow (5 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the StateGraph workflow using LangGraph.\n",
        "\n",
        "Implement the \"Sequential design pattern\" by adding nodes for each step (question generation, data retrieval/storage, report drafting) in sequence and connects them with edges to define the sequential flow from START to END."
      ],
      "metadata": {
        "id": "WuHCKdIPBw18"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "rOtcyVXKrN8j"
      },
      "outputs": [],
      "source": [
        "# Initialize the Graph\n",
        "graph = StateGraph(CompetitiveAnalysisState)\n",
        "\n",
        "# Add the nodes to the graph\n",
        "graph.add_node(\"question_generator\", run_question_generator)\n",
        "graph.add_node(\"data_retrieval_storage\", run_data_retrieval_storage)\n",
        "graph.add_node(\"report_drafter\", run_report_drafter)\n",
        "\n",
        "# Define the sequential flow\n",
        "graph.add_edge(START, \"question_generator\")\n",
        "graph.add_edge(\"question_generator\", \"data_retrieval_storage\")\n",
        "graph.add_edge(\"data_retrieval_storage\", \"report_drafter\")\n",
        "graph.add_edge(\"report_drafter\", END)\n",
        "\n",
        "# Compile the workflow\n",
        "competitive_analysis = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jYytY9MjrXcK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "69e572bd-c14e-45d5-cb47-ffa4bd449093"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "try:\n",
        "    display(Image(competitive_analysis.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    print(\"some error\")\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkI37OKLqsSb"
      },
      "source": [
        "def run_data_retrieval_storage(state: CompetitiveAnalysisState) -> CompetitiveAnalysisState:\n",
        "    print(\"[NODE]: run_data_retrieval_storage\")\n",
        "    if not state.question_list:\n",
        "        state.error_message = \"No questions generated.\"\n",
        "        return state\n",
        "\n",
        "    human_message_content = f\"Questions: {state.question_list}\"\n",
        "    print(f\"Invoking data_retrieval_storage_agent with: {human_message_content}\")\n",
        "    response = data_retrieval_storage_agent.invoke({\"messages\": [HumanMessage(content=human_message_content)]})\n",
        "\n",
        "    qna_results_from_tool = None\n",
        "    chromadb_status_from_tool = None\n",
        "\n",
        "    # Iterate through messages to find specific tool outputs\n",
        "    # Iterate in reverse as the latest tool outputs are usually towards the end\n",
        "    for msg in reversed(response.get(\"messages\", [])):\n",
        "        if hasattr(msg, \"type\") and msg.type == \"tool\" and hasattr(msg, \"name\"):\n",
        "            if msg.name == \"fetch_search_results\":\n",
        "                try:\n",
        "                    # Assuming fetch_search_results returns a JSON string of List[Dict]\n",
        "                    qna_results_from_tool = json.loads(msg.content)\n",
        "                    print(f\"[FETCH SEARCH RESULTS]: Found {len(qna_results_from_tool)} results.\")\n",
        "                except json.JSONDecodeError as e:\n",
        "                    state.error_message = f\"Failed to parse fetch_search_results output: {str(e)}\"\n",
        "                    print(f\"[ERROR]: {state.error_message}\")\n",
        "                # Only extract the first occurrence (most recent if iterating in reverse)\n",
        "                if qna_results_from_tool is not None: continue\n",
        "\n",
        "            elif msg.name == \"store_in_chromadb\":\n",
        "                try:\n",
        "                    # Assuming store_in_chromadb returns a JSON string of Dict {\"chromadb_insert_status\": bool}\n",
        "                    chromadb_output = json.loads(msg.content)\n",
        "                    chromadb_status_from_tool = chromadb_output.get(\"chromadb_insert_status\", False)\n",
        "                    print(f\"[CHROMADB INSERT STATUS]: {chromadb_status_from_tool}\")\n",
        "                except json.JSONDecodeError as e:\n",
        "                    state.error_message = f\"Failed to parse store_in_chromadb output: {str(e)}\"\n",
        "                    print(f\"[ERROR]: {state.error_message}\")\n",
        "                # Only extract the first occurrence (most recent if iterating in reverse)\n",
        "                if chromadb_status_from_tool is not None: continue\n",
        "\n",
        "\n",
        "    # Update state based on extracted tool outputs\n",
        "    if qna_results_from_tool is None:\n",
        "        state.error_message = state.error_message or \"Could not find valid output from 'fetch_search_results' tool.\"\n",
        "        print(f\"[ERROR]: {state.error_message}\")\n",
        "        state.qna_results = [] # Ensure it's an empty list if not found\n",
        "    else:\n",
        "        state.qna_results = qna_results_from_tool\n",
        "\n",
        "    if chromadb_status_from_tool is None:\n",
        "        state.error_message = state.error_message or \"Could not find valid output from 'store_in_chromadb' tool.\"\n",
        "        print(f\"[ERROR]: {state.error_message}\")\n",
        "        state.chromadb_insert_status = False # Ensure it's False if not found\n",
        "    else:\n",
        "        state.chromadb_insert_status = chromadb_status_from_tool\n",
        "\n",
        "    return state"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYSPEgE-reid"
      },
      "source": [
        "# **Execution (1 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invoking the workflow with the company  name as input."
      ],
      "metadata": {
        "id": "h_dJ0jsNBTCe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "FIATQePtrckM",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17ec0fcc-b933-482f-cb4f-acee55787ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NODE]: run_question_generator\n",
            "[INSIDE TOOL] suggest_questions\n",
            "[Identified SECTOR] Pharmaceuticals\n",
            "[IS VALID COMPANY] True\n",
            "[QUESTION GENERATED LIST] 5 questions\n",
            "[PARSED OUTPUT]: sector=Pharmaceuticals, is_valid_company=True, questions=5\n",
            "[NODE]: run_data_retrieval_storage\n",
            "[NODE]: run_report_drafter\n",
            "[RETRIEVED CONTEXT]: abbvie's products compete with similar offerings from other pharmaceutical companies in terms of pricing, efficacy, and technology, particularly in immunology and oncology segments. pricing strategies...\n",
            "[REPORT GENERATED]: # AbbVie Competitor Analysis Report\n",
            "\n",
            "## Overview\n",
            "AbbVie operates in the highly competitive Pharmaceuticals sector, focusing primarily on immunology and oncology. The company’s product offerings are ch...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# AbbVie Competitor Analysis Report\n\n## Overview\nAbbVie operates in the highly competitive Pharmaceuticals sector, focusing primarily on immunology and oncology. The company’s product offerings are characterized by their innovative biologics and proprietary therapies, which provide a competitive edge in a market that is increasingly driven by efficacy, pricing, and technological advancements.\n\n## Market Positioning\nAbbVie’s strategic focus on biologics and proprietary therapies enhances its market positioning. The company employs competitive pricing strategies and emphasizes innovation to differentiate its products from those of key competitors. \n\n### Key Competitors\nAbbVie faces significant competition from several major pharmaceutical companies, including:\n- **Johnson & Johnson**\n- **Pfizer**\n- **Roche**\n- **Merck**\n- **Amgen**\n- **AstraZeneca**\n- **Eli Lilly**\n\nAmong these, Merck is a direct competitor, particularly in the oncology and immunotherapy segments, where both companies are vying for market share.\n\n## Strengths and Weaknesses\n### Strengths\n- **Robust Portfolios**: AbbVie has strong offerings in immunology and oncology, which are critical growth areas in the pharmaceutical market.\n- **Innovation**: The company’s commitment to research and development allows it to introduce cutting-edge therapies that meet evolving patient needs.\n\n### Weaknesses\n- **Patent Expirations**: AbbVie faces challenges from the expiration of patents on key products, which can lead to increased competition from biosimilars.\n- **Biosimilar Competition**: The rise of biosimilars poses a threat to AbbVie’s market share and pricing power.\n\n## Market Trends\nCurrent trends in the pharmaceutical sector include:\n- **Rising Demand for Biologics**: There is an increasing preference for biologics and targeted therapies, which AbbVie is well-positioned to capitalize on.\n- **Digital Transformation**: The integration of digital technologies in pharmaceutical manufacturing is reshaping the industry, offering opportunities for efficiency and innovation.\n\n## Strategic Recommendations\nTo enhance its competitive position, AbbVie should consider the following strategies:\n1. **Focus on High-Growth Therapies**: Invest in the development of therapies that target high-growth areas within immunology and oncology.\n2. **Digital Transformation**: Leverage AI and advanced drug delivery systems to improve manufacturing processes and enhance product offerings.\n3. **Strategic Acquisitions**: Pursue acquisitions that complement AbbVie’s existing portfolio and expand its capabilities in high-demand therapeutic areas.\n4. **Partnerships and Collaborations**: Engage in international collaborations to bolster market presence and share resources for research and development.\n\n## Conclusion\nAbbVie is well-positioned in the Pharmaceuticals sector, particularly in immunology and oncology, but must navigate challenges such as patent expirations and increasing biosimilar competition. By focusing on innovation, digital transformation, and strategic partnerships, AbbVie can strengthen its market position and continue to thrive in a competitive landscape."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# sample input -> Tesla, Infosys, Deloitte, Great Learning\n",
        "# Input configuration\n",
        "input_state = {\n",
        "    \"company_name\": \"AbbVie\",\n",
        "    \"max_num_of_questions\": 5\n",
        "}\n",
        "\n",
        "# Run the pipeline\n",
        "result = competitive_analysis.invoke(input_state)\n",
        "\n",
        "# Display the final report\n",
        "display(Markdown(result['report']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For better readability, displaying the report in Markdown format"
      ],
      "metadata": {
        "id": "R-sRmRz0Bnzl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "g869HxlUr3RA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9209512e-b0db-4978-9ad0-eecef5e05676"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# AbbVie Competitor Analysis Report\n\n## Overview\nAbbVie operates in the highly competitive Pharmaceuticals sector, focusing primarily on immunology and oncology. The company’s product offerings are characterized by their innovative biologics and proprietary therapies, which provide a competitive edge in a market that is increasingly driven by efficacy, pricing, and technological advancements.\n\n## Market Positioning\nAbbVie’s strategic focus on biologics and proprietary therapies enhances its market positioning. The company employs competitive pricing strategies and emphasizes innovation to differentiate its products from those of key competitors. \n\n### Key Competitors\nAbbVie faces significant competition from several major pharmaceutical companies, including:\n- **Johnson & Johnson**\n- **Pfizer**\n- **Roche**\n- **Merck**\n- **Amgen**\n- **AstraZeneca**\n- **Eli Lilly**\n\nAmong these, Merck is a direct competitor, particularly in the oncology and immunotherapy segments, where both companies are vying for market share.\n\n## Strengths and Weaknesses\n### Strengths\n- **Robust Portfolios**: AbbVie has strong offerings in immunology and oncology, which are critical growth areas in the pharmaceutical market.\n- **Innovation**: The company’s commitment to research and development allows it to introduce cutting-edge therapies that meet evolving patient needs.\n\n### Weaknesses\n- **Patent Expirations**: AbbVie faces challenges from the expiration of patents on key products, which can lead to increased competition from biosimilars.\n- **Biosimilar Competition**: The rise of biosimilars poses a threat to AbbVie’s market share and pricing power.\n\n## Market Trends\nCurrent trends in the pharmaceutical sector include:\n- **Rising Demand for Biologics**: There is an increasing preference for biologics and targeted therapies, which AbbVie is well-positioned to capitalize on.\n- **Digital Transformation**: The integration of digital technologies in pharmaceutical manufacturing is reshaping the industry, offering opportunities for efficiency and innovation.\n\n## Strategic Recommendations\nTo enhance its competitive position, AbbVie should consider the following strategies:\n1. **Focus on High-Growth Therapies**: Invest in the development of therapies that target high-growth areas within immunology and oncology.\n2. **Digital Transformation**: Leverage AI and advanced drug delivery systems to improve manufacturing processes and enhance product offerings.\n3. **Strategic Acquisitions**: Pursue acquisitions that complement AbbVie’s existing portfolio and expand its capabilities in high-demand therapeutic areas.\n4. **Partnerships and Collaborations**: Engage in international collaborations to bolster market presence and share resources for research and development.\n\n## Conclusion\nAbbVie is well-positioned in the Pharmaceuticals sector, particularly in immunology and oncology, but must navigate challenges such as patent expirations and increasing biosimilar competition. By focusing on innovation, digital transformation, and strategic partnerships, AbbVie can strengthen its market position and continue to thrive in a competitive landscape."
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(result['report']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}